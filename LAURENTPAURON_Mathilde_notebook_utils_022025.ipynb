{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad8b3e6",
   "metadata": {},
   "source": [
    "#Transformation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df  # ✅ Stocker tout le DataFrame\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"filename\"]  # ✅ Accéder au chemin depuis df\n",
    "        label = self.df.iloc[idx][\"breed\"]  # ✅ Récupérer le label\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        if self.transforms:\n",
    "            # for transform in self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ccb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.GaussianBlur(3),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd681cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "      transforms.RandomHorizontalFlip(0.5),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_transfert = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.GaussianBlur(3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment_transfert = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
